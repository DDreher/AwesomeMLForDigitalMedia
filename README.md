# Awesome Machine Learning for Digital Media
A curated list of resources crossing the gap between digital media (computer vision, computer graphics, animation, vfx,...) and machine learning.

_Feel free to contribute! Send me a pull request or contact me [@Dan_Dreher_](https://twitter.com/https://twitter.com/dan_dreher_)_

____

## Table of Contents

* [Character Animation](#character-animation)
* [Computer Graphics](#computer-graphics)
* [Neural Rendering](#neural-rendering)
* [Visual Computing](#visual-computing)

## Character Animation

### Papers

* **Learned Motion Matching** (2020), Holden et al. [[link]](http://theorangeduck.com/page/learned-motion-matching) [[pdf]](http://theorangeduck.com/media/uploads/other_stuff/Learned_Motion_Matching.pdf)

* **Local Motion Phases for Learning Multi-Contact Character Movements** (2020), Starke et al. [[pdf]](https://github.com/sebastianstarke/AI4Animation/raw/master/Media/SIGGRAPH_2020/Paper.pdf)

* **Neural state machine for character-scene interactions** (2019), Starke et al. [[pdf]](https://github.com/sebastianstarke/AI4Animation/raw/master/Media/SIGGRAPH_Asia_2019/Paper.pdf)

* **DReCon: Data-Driven Responsive Control of Physics-Based Characters** (2019), Bergamin et al. [[link]](https://montreal.ubisoft.com/en/drecon-data-driven-responsive-control-of-physics-based-characters/) [[pdf]](https://static-wordpress.akamaized.net/montreal.ubisoft.com/wp-content/uploads/2019/11/13214229/DReCon.pdf)

* **Mode-adaptive neural networks for quadruped motion control** (2018), Zhang et al. [[pdf]](https://github.com/sebastianstarke/AI4Animation/raw/master/Media/SIGGRAPH_2018/Paper.pdf)

* **Phase-Functioned Neural Networks for Character Control** (2017), Holden et al. [[pdf]](http://theorangeduck.com/media/uploads/other_stuff/phasefunction.pdf)

### Datasets

* **LAFAN1 - Ubisoft La Forge Animation Dataset** (2020), Harvey et al. [[link]](https://github.com/ubisoft/Ubisoft-LaForge-Animation-Dataset)

### Projects

* **AI4Animation: Deep Learning, Character Animation, Control** [[link]](https://github.com/sebastianstarke/AI4Animation)

## Computer Graphics

### Papers

* **Neural Supersampling for Real-time Rendering** (2020), Xiao et al. [[link]](https://research.fb.com/blog/2020/07/introducing-neural-supersampling-for-real-time-rendering/) [[pdf]](https://research.fb.com/wp-content/uploads/2020/06/Neural-Supersampling-for-Real-time-Rendering.pdf)

* **Deep Shading: Convolutional Neural Networks for Screen-Space Shading** (2017), Nalbach et al. [[link]](http://deep-shading-datasets.mpi-inf.mpg.de/) [[pdf]](http://deep-shading-datasets.mpi-inf.mpg.de/deep-shading.pdf)

### Courses

* **CreativeAI: Deep Learning for Graphics** (2019), Mitra et al. [[link]](https://geometry.cs.ucl.ac.uk/creativeai/)

## Neural Rendering

### Papers

* **State of the Art on Neural Rendering** (2020), Tewari et al. [[link]](http://www.niessnerlab.org/projects/tewari2020neuralrendering.html) [[pdf]](https://arxiv.org/pdf/2004.03805.pdf)

* **Learning to Simulate Dynamic Environments with GameGAN** (2020), Kim et al. [[link]](https://nv-tlabs.github.io/gameGAN/) [[pdf]](https://arxiv.org/pdf/2005.12126.pdf)

* **Semantic Image Synthesis with Spatially-Adaptive Normalization** (2019), Park et al. [[link]](https://nvlabs.github.io/SPADE/) [[pdf]](https://arxiv.org/pdf/1903.07291.pdf)

* **Face2Face: Real-time Face Capture and Reenactment of RGB Videos** (2019), Thies et al. [[link]](http://www.niessnerlab.org/projects/thies2018face.html) [[pdf]](http://www.niessnerlab.org/papers/2019/8facetoface/thies2018face.pdf)


### Talks

* **Neural Rendering (CVPR 2020)** (2020) [[link]](https://www.youtube.com/watch?v=LCTYRqW-ne8)

## Visual Computing

### Talks

* **TUM AI Lecture Series - AI for 3D Content Creation** (2020), Sanja Fidler [[link]](https://www.youtube.com/watch?v=pTTxPq8uZmg&feature=youtu.be)

____

# License

[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)

