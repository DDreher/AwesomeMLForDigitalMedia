![banner](https://github.com/DDreher/awesome-ml-for-digital-media/blob/master/assets/banner.png)

A curated list of resources closing the gap between machine learning and digital media (computer graphics, computer vision, computational imaging, animation, vfx, game development,...).

This research field is rather broad and resources tend to intersect multiple fields at the same time.
I try to sort them into the category that I believe is most fitting.

_Feel free to contribute! Send a pull request or contact me [@Dan_Dreher_](https://twitter.com/dan_dreher_)_

_Looking for like-minded researchers, want to discuss an interesting paper you found or want to propose a contribution? Join the community on [Discord](https://discord.gg/8t9K2zQ)!_
____

## Table of Contents

* [Character Animation](#character-animation)
* [Computational Imaging](#computer-graphics)
* [Computer Graphics](#computer-graphics)
* [Computer Vision](#computer-vision)
* [Neural Rendering](#neural-rendering)
* [Visual Computing](#visual-computing)

## Character Animation

### Papers

* **RigNet: Neural Rigging for Articulated Characters** (2020), Xu et al. [[link]](https://zhan-xu.github.io/rig-net/) [[pdf]](https://people.cs.umass.edu/~zhanxu/papers/RigNet.pdf)

* **Learned Motion Matching** (2020), Holden et al. [[link]](http://theorangeduck.com/page/learned-motion-matching) [[pdf]](http://theorangeduck.com/media/uploads/other_stuff/Learned_Motion_Matching.pdf)

* **Local Motion Phases for Learning Multi-Contact Character Movements** (2020), Starke et al. [[link]](https://github.com/sebastianstarke/AI4Animation) [[pdf]](https://github.com/sebastianstarke/AI4Animation/raw/master/Media/SIGGRAPH_2020/Paper.pdf)

* **Neural state machine for character-scene interactions** (2019), Starke et al. [[link]](https://github.com/sebastianstarke/AI4Animation) [[pdf]](https://github.com/sebastianstarke/AI4Animation/raw/master/Media/SIGGRAPH_Asia_2019/Paper.pdf)

* **DReCon: Data-Driven Responsive Control of Physics-Based Characters** (2019), Bergamin et al. [[link]](https://montreal.ubisoft.com/en/drecon-data-driven-responsive-control-of-physics-based-characters/) [[pdf]](https://static-wordpress.akamaized.net/montreal.ubisoft.com/wp-content/uploads/2019/11/13214229/DReCon.pdf)

* **Mode-adaptive neural networks for quadruped motion control** (2018), Zhang et al. [[link]](https://github.com/sebastianstarke/AI4Animation) [[pdf]](https://github.com/sebastianstarke/AI4Animation/raw/master/Media/SIGGRAPH_2018/Paper.pdf)

* **Phase-Functioned Neural Networks for Character Control** (2017), Holden et al. [[link]](http://theorangeduck.com/page/phase-functioned-neural-networks-character-control) [[pdf]](http://theorangeduck.com/media/uploads/other_stuff/phasefunction.pdf)

### Datasets

* **LAFAN1 - Ubisoft La Forge Animation Dataset** (2020), Harvey et al. [[link]](https://github.com/ubisoft/Ubisoft-LaForge-Animation-Dataset)

### Projects

* **AI4Animation: Deep Learning, Character Animation, Control** [[link]](https://github.com/sebastianstarke/AI4Animation)

## Computational Imaging

### Papers

* **Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network** (2016), Ledig et al. [[link]](https://arxiv.org/abs/1609.04802) [[pdf]](https://arxiv.org/pdf/1609.04802)

## Computer Graphics

### Papers

* **MaterialGAN: Reflectance Capture using a Generative SVBRDF Model** (2020), Guo et al. [[link]](https://shuangz.com/projects/materialgan-sa20/) [[pdf]](https://shuangz.com/projects/materialgan-sa20/materialgan-sa20.pdf)

* **Neural Supersampling for Real-time Rendering** (2020), Xiao et al. [[link]](https://research.fb.com/blog/2020/07/introducing-neural-supersampling-for-real-time-rendering/) [[pdf]](https://research.fb.com/wp-content/uploads/2020/06/Neural-Supersampling-for-Real-time-Rendering.pdf)

* **Using Deep Convolutional Neural Networks to Detect Rendered Glitches in Video Games** (2020), Ling et al. [[link]](https://www.ea.com/seed/news/using-deep-convolutional-neural-networks-detect-glitches?Campaign_Source=ea+insiders&es_id=b22058bee4) [[pdf]](https://media.contentapi.ea.com/content/dam/ea/seed/presentations/seed-using-deep-convolutional-neural-networks-detect-glitches-paper.pdf)

* **Neural Network Ambient Occlusion** (2016), Holden et al. [[link]](http://theorangeduck.com/page/neural-network-ambient-occlusion) [[pdf]](http://theorangeduck.com/media/uploads/other_stuff/nnao.pdf)

### Talks / Courses / Tutorials / Workshops

* **CreativeAI: Deep Learning for Graphics** (2019), Mitra et al. [[link]](https://geometry.cs.ucl.ac.uk/creativeai/)

## Computer Vision

### Talks / Courses / Tutorials / Workshops

* **3DGV: Seminar on 3D Geometry and Vision** (2020) [[link]](https://3dgv.github.io/)

## Neural Rendering

### Papers

* **State of the Art on Neural Rendering** (2020), Tewari et al. [[link]](http://www.niessnerlab.org/projects/tewari2020neuralrendering.html) [[pdf]](https://arxiv.org/pdf/2004.03805.pdf)

* **X-Fields: Implicit Neural View-, Light- and Time-Image Interpolation** (2020), Bemana et al. [[link]](http://xfields.mpi-inf.mpg.de/) [[pdf]](http://xfields.mpi-inf.mpg.de/paper/X_Fields__siggasia_2020.pdf)

* **Learning to Simulate Dynamic Environments with GameGAN** (2020), Kim et al. [[link]](https://nv-tlabs.github.io/gameGAN/) [[pdf]](https://arxiv.org/pdf/2005.12126.pdf)

* **Semantic Image Synthesis with Spatially-Adaptive Normalization** (2019), Park et al. [[link]](https://nvlabs.github.io/SPADE/) [[pdf]](https://arxiv.org/pdf/1903.07291.pdf)

* **VR Facial Animation via Multiview Image Translation** (2019), Wei et al. [[link]](https://research.fb.com/publications/vr-facial-animation-via-multiview-image-translation/) [[pdf]](https://research.fb.com/wp-content/uploads/2019/06/VR-Facial-Animation-via-Multiview-Image-Translation.pdf)

* **Face2Face: Real-time Face Capture and Reenactment of RGB Videos** (2019), Thies et al. [[link]](http://www.niessnerlab.org/projects/thies2018face.html) [[pdf]](http://www.niessnerlab.org/papers/2019/8facetoface/thies2018face.pdf)

* **Deep Appearance Models for Face Rendering** (2018), Lombardi et al. [[link]](
https://research.fb.com/publications/deep-appearance-models-for-face-rendering/) [[pdf]](https://research.fb.com/wp-content/uploads/2018/08/Deep-Appearance-Models-for-Face-Rendering.pdf)

* **Deep Shading: Convolutional Neural Networks for Screen-Space Shading** (2017), Nalbach et al. [[link]](http://deep-shading-datasets.mpi-inf.mpg.de/) [[pdf]](http://deep-shading-datasets.mpi-inf.mpg.de/deep-shading.pdf)

### Talks / Courses / Tutorials / Workshops

* **Neural Rendering (CVPR Tutorial)** (2020) [[link]](https://www.neuralrender.com/) [[video 1]](https://www.youtube.com/watch?v=LCTYRqW-ne8) [[video 2]](https://www.youtube.com/watch?v=JlyGNvbGKB8&feature=youtu.be)

## Visual Computing

### Talks / Courses / Tutorials / Workshops

* **TUM AI Lecture Series - AI for 3D Content Creation** (2020), Sanja Fidler [[video]](https://www.youtube.com/watch?v=pTTxPq8uZmg&feature=youtu.be)

____

# License

[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)

