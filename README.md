# Awesome Machine Learning for Digital Media
A curated list of resources crossing the gap between digital media (computer vision, computer graphics, animation, vfx,...) and machine learning.

_Feel free to contribute! Send me a pull request or contact me [@Dan_Dreher_](https://twitter.com/dan_dreher_)_

____

## Table of Contents

* [Character Animation](#character-animation)
* [Computer Graphics](#computer-graphics)
* [Neural Rendering](#neural-rendering)
* [Visual Computing](#visual-computing)

## Character Animation

### Papers

* **Learned Motion Matching** (2020), Holden et al. [[link]](http://theorangeduck.com/page/learned-motion-matching) [[pdf]](http://theorangeduck.com/media/uploads/other_stuff/Learned_Motion_Matching.pdf)

* **Local Motion Phases for Learning Multi-Contact Character Movements** (2020), Starke et al. [[link]](https://github.com/sebastianstarke/AI4Animation) [[pdf]](https://github.com/sebastianstarke/AI4Animation/raw/master/Media/SIGGRAPH_2020/Paper.pdf)

* **Neural state machine for character-scene interactions** (2019), Starke et al. [[link]](https://github.com/sebastianstarke/AI4Animation) [[pdf]](https://github.com/sebastianstarke/AI4Animation/raw/master/Media/SIGGRAPH_Asia_2019/Paper.pdf)

* **DReCon: Data-Driven Responsive Control of Physics-Based Characters** (2019), Bergamin et al. [[link]](https://montreal.ubisoft.com/en/drecon-data-driven-responsive-control-of-physics-based-characters/) [[pdf]](https://static-wordpress.akamaized.net/montreal.ubisoft.com/wp-content/uploads/2019/11/13214229/DReCon.pdf)

* **Mode-adaptive neural networks for quadruped motion control** (2018), Zhang et al. [[link]](https://github.com/sebastianstarke/AI4Animation) [[pdf]](https://github.com/sebastianstarke/AI4Animation/raw/master/Media/SIGGRAPH_2018/Paper.pdf)

* **Phase-Functioned Neural Networks for Character Control** (2017), Holden et al. [[link]](http://theorangeduck.com/page/phase-functioned-neural-networks-character-control) [[pdf]](http://theorangeduck.com/media/uploads/other_stuff/phasefunction.pdf)

### Datasets

* **LAFAN1 - Ubisoft La Forge Animation Dataset** (2020), Harvey et al. [[link]](https://github.com/ubisoft/Ubisoft-LaForge-Animation-Dataset)

### Projects

* **AI4Animation: Deep Learning, Character Animation, Control** [[link]](https://github.com/sebastianstarke/AI4Animation)

## Computer Graphics

### Papers

* **Neural Supersampling for Real-time Rendering** (2020), Xiao et al. [[link]](https://research.fb.com/blog/2020/07/introducing-neural-supersampling-for-real-time-rendering/) [[pdf]](https://research.fb.com/wp-content/uploads/2020/06/Neural-Supersampling-for-Real-time-Rendering.pdf)

* **Using Deep Convolutional Neural Networks to Detect Rendered Glitches in Video Games** (2020), Ling et al. [[link]](https://www.ea.com/seed/news/using-deep-convolutional-neural-networks-detect-glitches?Campaign_Source=ea+insiders&es_id=b22058bee4) [[pdf]](https://media.contentapi.ea.com/content/dam/ea/seed/presentations/seed-using-deep-convolutional-neural-networks-detect-glitches-paper.pdf)

* **Neural Network Ambient Occlusion** (2016), Holden et al. [[link]](http://theorangeduck.com/page/neural-network-ambient-occlusion) [[pdf]](http://theorangeduck.com/media/uploads/other_stuff/nnao.pdf)

### Talks / Courses / Tutorials / Workshops

* **CreativeAI: Deep Learning for Graphics** (2019), Mitra et al. [[link]](https://geometry.cs.ucl.ac.uk/creativeai/)

## Neural Rendering

### Papers

* **State of the Art on Neural Rendering** (2020), Tewari et al. [[link]](http://www.niessnerlab.org/projects/tewari2020neuralrendering.html) [[pdf]](https://arxiv.org/pdf/2004.03805.pdf)

* **X-Fields: Implicit Neural View-, Light- and Time-Image Interpolation** (2020), Bemana et al. [[link]](http://xfields.mpi-inf.mpg.de/) [[pdf]](http://xfields.mpi-inf.mpg.de/paper/X_Fields__siggasia_2020.pdf)

* **Learning to Simulate Dynamic Environments with GameGAN** (2020), Kim et al. [[link]](https://nv-tlabs.github.io/gameGAN/) [[pdf]](https://arxiv.org/pdf/2005.12126.pdf)

* **Semantic Image Synthesis with Spatially-Adaptive Normalization** (2019), Park et al. [[link]](https://nvlabs.github.io/SPADE/) [[pdf]](https://arxiv.org/pdf/1903.07291.pdf)

* **VR Facial Animation via Multiview Image Translation** (2019), Wei et al. [[link]](https://research.fb.com/publications/vr-facial-animation-via-multiview-image-translation/) [[pdf]](https://research.fb.com/wp-content/uploads/2019/06/VR-Facial-Animation-via-Multiview-Image-Translation.pdf)

* **Face2Face: Real-time Face Capture and Reenactment of RGB Videos** (2019), Thies et al. [[link]](http://www.niessnerlab.org/projects/thies2018face.html) [[pdf]](http://www.niessnerlab.org/papers/2019/8facetoface/thies2018face.pdf)

* **Deep Appearance Models for Face Rendering** (2018), Lombardi et al. [[link]](
https://research.fb.com/publications/deep-appearance-models-for-face-rendering/) [[pdf]](https://research.fb.com/wp-content/uploads/2018/08/Deep-Appearance-Models-for-Face-Rendering.pdf)

* **Deep Shading: Convolutional Neural Networks for Screen-Space Shading** (2017), Nalbach et al. [[link]](http://deep-shading-datasets.mpi-inf.mpg.de/) [[pdf]](http://deep-shading-datasets.mpi-inf.mpg.de/deep-shading.pdf)

### Talks / Courses / Tutorials / Workshops

* **Neural Rendering (CVPR Tutorial)** (2020) [[link]](https://www.neuralrender.com/) [[video 1]](https://www.youtube.com/watch?v=LCTYRqW-ne8) [[video 2]](https://www.youtube.com/watch?v=JlyGNvbGKB8&feature=youtu.be)

## Visual Computing

### Talks / Courses / Tutorials / Workshops

* **TUM AI Lecture Series - AI for 3D Content Creation** (2020), Sanja Fidler [[video]](https://www.youtube.com/watch?v=pTTxPq8uZmg&feature=youtu.be)

____

# License

[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)

